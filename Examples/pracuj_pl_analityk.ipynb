{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17aba6d4-a71f-497e-bb72-abdec7458d05",
   "metadata": {},
   "source": [
    "## Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "009807cb-0138-482c-a74e-1577e9d47088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137ff9c6-278f-4416-8568-b1af92be2484",
   "metadata": {},
   "source": [
    "## Podstawowa konfiguracja.\n",
    "\n",
    "Tutaj ustawiamy podstawowe opcje naszego skryptu. **BASE_URL** to główny link, który jest podstawą naszego zeskrobywania - posiada w swoim ciągu znaków wszelkie filtry jakie ustawiliśmy na stronie:\n",
    "### https://www.pracuj.pl/praca \n",
    "możemy ustawić miasto, promień wyszukiwania wokół tego miasta, oferowaną pozycję i kategorii ogłoszeń.\n",
    "\n",
    "* **GECKODRIVER_FILEPATH** powinien kierować na plik wykonywujący geckodriver. Na Windowskie powinien prowadzić do pliku .exe. Na linuxie do katalogu /usr/bin/geckodriver.\n",
    "* **SCRIPT_DIR** i **CSV_FILEPATH** zapewniają, że nasza .csv powstanie w folderze wykonywania naszego skryptu jak używamy Jupytera. W innym przypadku należy odkomentować linijkę wyżej i skomentować tę widoczną teraz.\n",
    "* **CSV_HEADERS** ustala kolumny w pliku .csv.\n",
    "* **SCRAPE_CONFIG** ustala jakie informacje będziemy zeskrobywać ze stron ofert. Klucze powinny być zgodne z **CSV_HEADERS**, selektory z rzeczywistymi drogami .html na stronie ofert. Metoda **element** oznacza, że szukamy zapisamy tekst tam znajdujący się w jednym elemencie. Metoda **elements** z kolei utworzy listę elementów. Metoda **element_split1** i **element_split2** są dla elementów, gdzie pod jednym miejscem znajdują się dwa - przykładowo:\n",
    "\n",
    "* ul. Aleje Jerozolimskie,\n",
    "* Warszawa, Mazowieckie.\n",
    "##### **element_split1** złapie pierwszą część, a **element_split2** drugi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e22a2527-5ca3-4406-9e5e-2799f8eec703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfiguracja, wejdź na stronę www.pracuj.pl/praca/ i pofiltruj po chcianych wartościach, następnie tutaj przeklej i dodaj \"&pn={page_number}\" na końcu\n",
    "# Oferty stażu z Finansów / Ekonomii\n",
    "#BASE_URL_TEMPLATE = \"https://www.pracuj.pl/praca/warszawa;wp/finanse%20ekonomia;cc,5008?rd=30&et=1&pn={page_number}\"\n",
    "\n",
    "# Oferty stażu, asystentów i juniorów z frazy \"Analityk Danych\"\n",
    "BASE_URL_TEMPLATE = \"https://www.pracuj.pl/praca/analityk%20danych;kw/warszawa;wp?rd=30&et=1%2C3%2C17&pn={page_number}\"\n",
    "\n",
    "#Bardziej skomplikowany\n",
    "#BASE_URL_TEMPLATE = \"https://www.pracuj.pl/praca/warszawa;wp?rd=30&cc=5008%2C5015%2C5003%2C5032%2C5001&et=1%2C3&pn={page_number}\"\n",
    "\n",
    "# bcs=2 (Finanse/Ekonomia) 5008, 18 (IT-Admin), 1 (Bankowość), 16 (Ubezpieczenia), 5001 (Admin. biurowa)\n",
    "#cc=5008%2C5015%2C5003%2C5032%2C5001\n",
    "# et=1 (Asystent), 2 (Praktykant/Stażysta)\n",
    "# wp/warszawa - lokalizacja Warszawa\n",
    "# rd=30 - promień 30km\n",
    "# pn - numer strony\n",
    "\n",
    "#ma tylko dwie strony, na rzecz testu\n",
    "# BASE_URL_TEMPLATE = \"https://www.pracuj.pl/praca/warszawa;wp?rd=30&cc=5003%2C5015001%2C5015002%2C5015003%2C5015005%2C5015006%2C5015007&et=1%2C3&pn={page_number}\"\n",
    "\n",
    "GECKODRIVER_FILEPATH = '/usr/bin/geckodriver'\n",
    "#ustawienie folderu ze skryptem\n",
    "#SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__)) # miejsce folderu ze skryptem - używać dla suchego skryptu python\n",
    "SCRIPT_DIR = os.getcwd()  # miejsce dla folderu ze skryptem - używać dla jupytera\n",
    "CSV_FILEPATH = os.path.join(SCRIPT_DIR, \"pracuj_pl_oferty.csv\")\n",
    "CSV_HEADERS = [\n",
    "    'offer_id',\n",
    "    'offer_url',\n",
    "    'position_name',\n",
    "    'employer_name',\n",
    "    'benefit_workplace_adress', # Metoda elementsplit0\n",
    "    'benefit_workplace_city',     # Metoda elementsplit1\n",
    "    'benefit_contracts',\n",
    "    'benefit_work_schedule',\n",
    "    'benefit_employment_type_name',\n",
    "    'work_modes',\n",
    "    'immediate_employment',\n",
    "    'many_vacancies',       # Metoda elementsplit0\n",
    "    'many_vacancies_count',        # Metoda elementsplit1\n",
    "    'salary_per_contract_section',\n",
    "    'remote_recruitment',\n",
    "    'ukrainian_friendly',\n",
    "    'it_specializations',\n",
    "    'salary_components',\n",
    "    'required_languages',\n",
    "    'work_hours',\n",
    "    'shift_work',\n",
    "    'work_days',\n",
    "    'paycheck_period',\n",
    "    'earning_amount',\n",
    "    'technologies_expected',\n",
    "    'technologies_optional',\n",
    "    'benefit_titles',\n",
    "    'responsibilities_section',\n",
    "    'requirements_section',\n",
    "    'offered_section',\n",
    "    'description_block',\n",
    "    'additional_module_section'\n",
    "]\n",
    "SCRAPE_CONFIG = [\n",
    "    {'key': 'position_name', 'selector': 'h1[data-test=\"text-positionName\"]', 'method': 'element'},\n",
    "    {'key': 'employer_name', 'selector': 'h2[data-test=\"text-employerName\"]', 'method': 'element'},\n",
    "    {'key': 'benefit_workplace_adress', 'selector': '[data-test=\"sections-benefit-workplaces\"]', 'method': 'element_split0'},\n",
    "    {'key': 'benefit_workplace_city', 'selector': '[data-test=\"sections-benefit-workplaces\"]', 'method': 'element_split1'},\n",
    "    {'key': 'benefit_contracts', 'selector': '[data-test=\"sections-benefit-contracts\"]', 'method': 'element'},\n",
    "    {'key': 'benefit_work_schedule', 'selector': '[data-test=\"sections-benefit-work-schedule\"]', 'method': 'element'},\n",
    "    {'key': 'benefit_employment_type_name', 'selector': '[data-test=\"sections-benefit-employment-type-name\"]', 'method': 'element'},\n",
    "    {'key': 'work_modes', 'selector': '[data-scroll-id=\"work-modes\"]', 'method': 'element'},\n",
    "    {'key': 'immediate_employment', 'selector': '[data-scroll-id=\"attribute-primary-immediate-employment\"]', 'method': 'element'},\n",
    "    {'key': 'many_vacancies', 'selector': '[data-scroll-id=\"attribute-primary-many-vacancies\"]', 'method': 'element_split0'},\n",
    "    {'key': 'many_vacancies_count', 'selector': '[data-scroll-id=\"attribute-primary-many-vacancies\"]', 'method': 'element_split1'},\n",
    "    {'key': 'salary_per_contract_section', 'selector': '[data-test=\"section-salaryPerContract\"]', 'method': 'element'},\n",
    "    {'key': 'remote_recruitment', 'selector': '[data-scroll-id=\"remote-recruitement\"]', 'method': 'element'},\n",
    "    {'key': 'ukrainian_friendly', 'selector': '[data-scroll-id=\"attribute-primary-ukrainian-friendly\"]', 'method': 'element'},\n",
    "    {'key': 'it_specializations', 'selector': '[data-test=\"it-specializations\"]', 'method': 'elements'},\n",
    "    {'key': 'salary_components', 'selector': '[data-test=\"salary-components\"]', 'method': 'element'},\n",
    "    {'key': 'required_languages', 'selector': '[data-test=\"required-languages\"]', 'method': 'element'},\n",
    "    {'key': 'work_hours', 'selector': '[data-test=\"work-hours\"]', 'method': 'element'},\n",
    "    {'key': 'shift_work', 'selector': '[data-test=\"shift-work\"]', 'method': 'element'},\n",
    "    {'key': 'work_days', 'selector': '[data-test=\"work-days\"]', 'method': 'element'},\n",
    "    {'key': 'paycheck_period', 'selector': '[data-test=\"paycheck-period\"]', 'method': 'element'},\n",
    "    {'key': 'earning_amount', 'selector': '[data-test=\"text-earningAmount\"]', 'method': 'element'},\n",
    "    {'key': 'technologies_expected', 'selector': '[data-test=\"item-technologies-expected\"]', 'method': 'elements'},\n",
    "    {'key': 'technologies_optional', 'selector': '[data-test=\"item-technologies-optional\"]', 'method': 'elements'},\n",
    "    {'key': 'benefit_titles', 'selector': '[data-test=\"text-benefit-title\"]', 'method': 'elements'},\n",
    "    {'key': 'responsibilities_section', 'selector': 'section[data-test=\"section-responsibilities\"]', 'method': 'element'},\n",
    "    {'key': 'requirements_section', 'selector': 'section[data-test=\"section-requirements\"]', 'method': 'element'},\n",
    "    {'key': 'offered_section', 'selector': 'section[data-test=\"section-offered\"]', 'method': 'element'},\n",
    "    {'key': 'description_block', 'selector': 'section[data-test=\"block-description\"]', 'method': 'element'},\n",
    "    {'key': 'additional_module_section', 'selector': 'section[data-test=\"section-additional-module\"]', 'method': 'element'},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6506c667-853f-48a9-9896-4bb0e588881b",
   "metadata": {},
   "source": [
    "## Funkcje pomocnicze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b12244a6-98a2-4e23-9817-1c9b62fa2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcje pomocnicze do bezpiecznego pobierania danych\n",
    "# Zwraca jeden text\n",
    "def safe_get_element(driver_or_element, by, value):\n",
    "    try:\n",
    "        return driver_or_element.find_element(by, value).text.strip()\n",
    "    except NoSuchElementException:\n",
    "        return None\n",
    "\n",
    "# Zwraca listę textów\n",
    "def safe_get_elements(driver_or_element, by, value):\n",
    "    try:\n",
    "        elements = driver_or_element.find_elements(by, value)\n",
    "        return [el.text.strip() for el in elements if el.text.strip()]\n",
    "    except NoSuchElementException:\n",
    "        return []\n",
    "# Zwraca html\n",
    "def get_element_html_or_none(driver_or_element, by, value):\n",
    "    try:\n",
    "        return driver_or_element.find_element(by, value).get_attribute('innerHTML').strip()\n",
    "    except NoSuchElementException:\n",
    "        return None\n",
    "\n",
    "# Dodaje słownik data_dict na koniec .csv-ki na końcu filepath\n",
    "def append_dict_to_csv(data_dict, filepath, fieldnames):\n",
    "    file_exists = os.path.isfile(filepath)\n",
    "    write_header = not file_exists or os.path.getsize(filepath) == 0\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames, extrasaction='ignore')\n",
    "            # extrasaction='ignore' spowoduje, że dodatkowe klucze w data_dict (niebędące w fieldnames) zostaną zignorowane\n",
    "            if write_header:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(data_dict)\n",
    "    except IOError as e:\n",
    "        print(f\"Błąd I/O:({e.errno}): {e.strerror} podczas pisania do {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Niespodziewany błąd: {e} podczas pisania do {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727cd70e-a3ad-4589-9891-7da6c317d868",
   "metadata": {},
   "source": [
    "## Inicjalizacja WebDrivera i akceptowanie ciasteczek\n",
    "\n",
    "Po wejściu na **BASE_URL** mogą pojawić się trzy pop-upy:\n",
    "* Za zaakceptowanie ciasteczek odpowiada **cookie_button**\n",
    "* Za zamknięcie okna logowania kontem Google **google_cross**\n",
    "* Za zaakceptowanie regulaminu prywatności **privacy_cross**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11158bab-01eb-4424-a76b-71fb7a436a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam scrapowanie...\n",
      "Błąd podczas akceptacji google'a.\n",
      "Błąd podczas akceptacji prywatności.\n",
      "Zaakceptowano wszystko.\n"
     ]
    }
   ],
   "source": [
    "# Inicjalizacja WebDrivera (Firefox)\n",
    "\n",
    "service = Service(GECKODRIVER_FILEPATH)\n",
    "driver = webdriver.Firefox(service=service)\n",
    "\n",
    "print(\"Rozpoczynam scrapowanie...\")\n",
    "# Akceptacja ciasteczek (jeśli się pojawi)\n",
    "# Najpierw otwieramy stronę bazową, aby obsłużyć ciasteczka\n",
    "driver.get(BASE_URL_TEMPLATE)\n",
    "time.sleep(2) # Czekamy na załadowanie strony i ewentualne pop-upy\n",
    "\n",
    "try:\n",
    "    cookie_button_selector = \"button[data-test='button-submitCookie']\"\n",
    "    cookie_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, cookie_button_selector))\n",
    "    )\n",
    "    cookie_button.click()\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Nie znaleziono przycisku akceptacji ciasteczek lub już zaakceptowano.\")\n",
    "except Exception as e:\n",
    "    print(f\"Błąd podczas akceptacji ciasteczek: {e}\")\n",
    "\n",
    "# Klikamy x na popupie od logowania się do google, znajduje się na innym iframie    \n",
    "try:\n",
    "    driver.switch_to.frame(driver.find_element(By.CSS_SELECTOR, \"iframe:nth-child(1)\"))\n",
    "    google_cross_selector = \"#close\"\n",
    "    google_cross = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, google_cross_selector))\n",
    "    )\n",
    "    google_cross.click()\n",
    "    driver.switch_to.default_content()\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Nie znaleziono przycisku zamknięcia logowania google lub już zaakceptowano.\")\n",
    "except Exception as e:\n",
    "     print(f\"Błąd podczas akceptacji google'a.\")\n",
    "\n",
    "# Klikamy x na popupie o prywatności\n",
    "try:\n",
    "    privacy_cross_selector = driver.find_element(By.XPATH, '//div[@role=\"dialog\"]//button')\n",
    "    privacy_cross_selector.click()\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Nie znaleziono przycisku akceptacji prywatności lub już zaakceptowano.\")\n",
    "except Exception as e:\n",
    "    print(f\"Błąd podczas akceptacji prywatności.\")\n",
    "\n",
    "print(\"Zaakceptowano wszystko.\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ba5149-fecd-4633-9bb6-3ba7955b83f4",
   "metadata": {},
   "source": [
    "## Stworzenie .csv i zbieranie linków do ofert\n",
    "\n",
    "Następnie sprawdzamy czy plik .csv już istnieje, jeżeli tak to zbieramy z niego już zapisane w nim **offer_id** do listy **offers_csv_ids**, aby nie powtarzać dla nich analizy, w przeciwnym przypadku tworzymy go z etykietami kolumn według **CSV_HEADERS**. Następnie wchodzimy na **BASE_URL**, znajdujemy na nim ilość stron ofert, a następnie przechodzimy przez nie, zbierając linki do każdej z ofert, których **offer_id** nie widnieje na naszej liście **offers_csv_ids**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f60ef9c5-193b-409c-b74a-a61d25468424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004111903\n",
      "1004094662\n",
      "1004096214\n",
      "1004107866\n",
      "1004093823\n",
      "1004106824\n",
      "1004121599\n",
      "1004127749\n",
      "1004109364\n",
      "1004126743\n",
      "1004094504\n",
      "1004089729\n",
      "1004083821\n",
      "1004097514\n",
      "1004094662\n",
      "1004116929\n",
      "1004075671\n",
      "1004112838\n",
      "1004092150\n",
      "1004088225\n",
      "1004103407\n",
      "1004077243\n",
      "1004110794\n",
      "1004128473\n",
      "1004132798\n",
      "1004101046\n",
      "1004102346\n",
      "1004108912\n",
      "1004115131\n",
      "1004088032\n",
      "1004087451\n",
      "1004106961\n",
      "1004116195\n",
      "1004121311\n",
      "1004096214\n",
      "1004096121\n",
      "1004128342\n",
      "1004134428\n",
      "1004075037\n",
      "1004077947\n",
      "1004075018\n",
      "1004118832\n",
      "1004094179\n",
      "1004094367\n",
      "1004124945\n",
      "1004111903\n",
      "1004089476\n",
      "1004120541\n",
      "1004103621\n",
      "1004075821\n",
      "1004075811\n",
      "1004122288\n",
      "1004101553\n",
      "1004110989\n",
      "1004100321\n",
      "1004108958\n",
      "1004116465\n",
      "1004108861\n",
      "1004079902\n",
      "1004079832\n",
      "1004078785\n",
      "1004098199\n",
      "1004129457\n",
      "1004116372\n",
      "1004115965\n",
      "1004090612\n",
      "1004106347\n",
      "1004114677\n",
      "1004095369\n",
      "1004107866\n",
      "1004088282\n",
      "1004112232\n",
      "1004082199\n",
      "1004081163\n",
      "1004094132\n",
      "1004120611\n",
      "1004125779\n",
      "1004132382\n",
      "1004099537\n",
      "1004117319\n",
      "1004086363\n",
      "1004107135\n",
      "1004092538\n",
      "1004116097\n",
      "1004086725\n",
      "1004086275\n",
      "1004085797\n",
      "1004074706\n",
      "1004088565\n",
      "1004074213\n",
      "1004081559\n",
      "1004080163\n",
      "1004079744\n",
      "1004082579\n",
      "1004112984\n",
      "1004075059\n",
      "1004072400\n",
      "1004106985\n",
      "1004073166\n",
      "1004095714\n",
      "1004078611\n",
      "1004090841\n",
      "1004074747\n",
      "1004072030\n",
      "1004090294\n",
      "\n",
      "Przechodzę na stronę: https://www.pracuj.pl/praca/analityk%20danych;kw/warszawa;wp?rd=30&et=1%2C3%2C17&pn=1\n",
      "Dodaję ID: 1004136898\n",
      "Dodaję ID: 1004137445\n",
      "Dodaję ID: 1004137445\n",
      "Dodaję ID: 1004137027\n",
      "Dodaję ID: 1004137141\n",
      "Dodaję ID: 1004137467\n",
      "Dodaję ID: 1004136625\n",
      "Dodaję ID: 1004135928\n",
      "Dodaję ID: 1004136898\n",
      "Znaleziono 9 unikalnych ofert na stronie 1.\n",
      "\n",
      "Przechodzę na stronę: https://www.pracuj.pl/praca/analityk%20danych;kw/warszawa;wp?rd=30&et=1%2C3%2C17&pn=2\n",
      "Znaleziono 0 unikalnych ofert na stronie 2.\n",
      "\n",
      "Przechodzę na stronę: https://www.pracuj.pl/praca/analityk%20danych;kw/warszawa;wp?rd=30&et=1%2C3%2C17&pn=3\n",
      "Znaleziono 0 unikalnych ofert na stronie 3.\n"
     ]
    }
   ],
   "source": [
    "#wyszukuje na stronie numer ostatniej strony\n",
    "max_page_text = driver.find_element(By.CSS_SELECTOR, '[data-test=\"top-pagination-max-page-number\"]').text\n",
    "max_page = int(max_page_text)\n",
    "\n",
    "# Tworzymy listę offer_id które już mamy w csv\n",
    "offer_csv_ids = []\n",
    "try:\n",
    "    with open(CSV_FILEPATH, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        \n",
    "        try:\n",
    "            # Przeczytaj pierwszy opis kolumny\n",
    "            header = next(reader)\n",
    "        except StopIteration:\n",
    "            # To oznacza że pliku nie ma\n",
    "            print(f\"Pliku .csv w {file_path}' nie ma.\")\n",
    "    \n",
    "        # Sprawdzamy cze \"offer_id\" jest pierwsze w wierszu\n",
    "        if not header or header[0] != 'offer_id':\n",
    "            actual_first_header = header[0] if header and len(header) > 0 else \"None or empty\"\n",
    "            print(f\"Error: Pierwszy opis kolumny w '{CSV_FILEPATH}' nie jest 'offer_id'. Zamiast niego jest: '{actual_first_header}'.\")\n",
    "            \n",
    "        # Przechodzimy po kolejnych wierszach\n",
    "        for row in reader:\n",
    "            print(row[0])\n",
    "            offer_csv_ids.append(row[0])        \n",
    "except FileNotFoundError:\n",
    "    print(f\"Nie znaleziono '{CSV_FILEPATH}'.\")\n",
    "except Exception as e:\n",
    "    # Wszystkie inne errory\n",
    "    print(f\"Niespodziewany błąd w: '{CSV_FILEPATH}': {e}\")\n",
    "\n",
    "# Mam nadzieję że to zmniejszy złożoność obliczeniową przy następnych sprawdzeniach\n",
    "offer_csv_ids.sort()\n",
    "\n",
    "\n",
    "# Przechodzimy po kolejnych stronach z ogłoszeniami\n",
    "offer_urls = []\n",
    "for page_number in range(1, max_page + 1):\n",
    "    current_page_url = BASE_URL_TEMPLATE.format(page_number=page_number)\n",
    "    print(f\"\\nPrzechodzę na stronę: {current_page_url}\")\n",
    "    driver.get(current_page_url)\n",
    "    time.sleep(1)\n",
    "    start_length = len(offer_urls)\n",
    "\n",
    "\n",
    "    #sprawdza czy oferty się załadowały\n",
    "    try:\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-test=\"section-offers\"]'))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        print(f\"Nie udało się załadować sekcji ofert na stronie {page_number}. Prawdopodobnie koniec wyników.\")\n",
    "    \n",
    "    # Tworzy listę dostępnych URL z \"/praca/\" i \"link-offer\" i sprawdzamy czy już wystąpiły w .csv\n",
    "    offer_links_elements = driver.find_elements(By.CSS_SELECTOR, 'a.offer-title__link[href^=\"/praca/\"], a[data-test=\"link-offer\"]')\n",
    "\n",
    "    for el in offer_links_elements:\n",
    "        try:\n",
    "            href = el.get_attribute('href')\n",
    "            # Sprawdza czy link jest poprawny\n",
    "            if href and href.startswith(\"https://www.pracuj.pl/praca/\"):\n",
    "                # Sprawdza czy dane id już jest w .csv\n",
    "                if(href.split(',oferta,')[-1].split('?')[0] not in offer_csv_ids):\n",
    "                    print(\"Dodaję ID: {id}\".format(id=href.split(',oferta,')[-1].split('?')[0]))\n",
    "                    offer_urls.append(href)\n",
    "        except Exception as e:\n",
    "            print(f\"Błąd przy pobieraniu href: {e}\")\n",
    "    \n",
    "    offer_urls = list(dict.fromkeys(offer_urls))\n",
    "    print(f\"Znaleziono {len(offer_urls)-start_length} unikalnych ofert na stronie {page_number}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad454219-f068-439f-9022-e97adf2902b5",
   "metadata": {},
   "source": [
    "## Zbieranie danych z poszczególnych linków\n",
    "\n",
    " Przechodzimy po liście **offer_uls** z poprzedniego punktu, która zawiera wszystkie unikalne linki z naszego zapytania. Dane z poszczególnych stron są zapisywane w \n",
    " słowniku **offer_data**, który ma klucze według zdefiniowanego **CSV_HEADERS**, a wartości są dodawanego według klucza, selektora i metody podanych w **SCRAPE_CONFIG**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb5fdc5d-07ac-48e8-be26-3ec17f5b4fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Przetwarzam ofertę: https://www.pracuj.pl/praca/mlodszy-analityk-mlodszy-specjalista-ds-kontrolingu-operacyjnego-controlling-warszawa-chelmzynska-249,oferta,1004136898?s=78322469&searchId=MTc0ODkwMzQxMjczOC4xMzU1&ref=top_boosterAI_L2_4_1_1\n",
      "Numer 1 o ID: 1004136898\n",
      "  Przetwarzam ofertę: https://www.pracuj.pl/praca/graduate-it-business-analyst-warszawa-grzybowska-78,oferta,1004137445?s=78322469&searchId=MTc0ODkwMzQxMjczOC4xMzU1&ref=top_boosterAI_L2_5_1_1\n",
      "Numer 2 o ID: 1004137445\n",
      "  Przetwarzam ofertę: https://www.pracuj.pl/praca/graduate-it-business-analyst-warszawa-grzybowska-78,oferta,1004137445?s=78322469&searchId=MTc0ODkwMzQxMjczOC4xMzU1\n",
      "Numer 3 o ID: 1004137445\n",
      "  Przetwarzam ofertę: https://www.pracuj.pl/praca/assistant-senior-assistant-deal-advisory-transaction-services-data-analytics-warszawa-inflancka-4a,oferta,1004137027?s=78322469&searchId=MTc0ODkwMzQxMjczOC4xMzU1\n",
      "Numer 4 o ID: 1004137027\n",
      "  Przetwarzam ofertę: https://www.pracuj.pl/praca/mlodszy-specjalista-ds-rozliczen-klientow-korporacyjnych-warszawa-zawodzie-5,oferta,1004137141?s=78322469&searchId=MTc0ODkwMzQxMjczOC4xMzU1\n",
      "Numer 5 o ID: 1004137141\n",
      "  Przetwarzam ofertę: https://www.pracuj.pl/praca/junior-performance-marketing-specialist-google-ads-facebook-ads-warszawa,oferta,1004137467?s=78322469&searchId=MTc0ODkwMzQxMjczOC4xMzU1\n",
      "Numer 6 o ID: 1004137467\n",
      "  Przetwarzam ofertę: https://www.pracuj.pl/praca/commodity-flow-trader-grodzisk-mazowiecki-romualda-traugutta-42a,oferta,1004136625?s=78322469&searchId=MTc0ODkwMzQxMjczOC4xMzU1\n",
      "Numer 7 o ID: 1004136625\n",
      "  Przetwarzam ofertę: https://www.pracuj.pl/praca/staz-w-dziale-strategic-planning-insights-warszawa-zelazna-51-53,oferta,1004135928?s=78322469&searchId=MTc0ODkwMzQxMjczOC4xMzU1\n",
      "Numer 8 o ID: 1004135928\n",
      "  Przetwarzam ofertę: https://www.pracuj.pl/praca/mlodszy-analityk-mlodszy-specjalista-ds-kontrolingu-operacyjnego-controlling-warszawa-chelmzynska-249,oferta,1004136898?s=78322469&searchId=MTc0ODkwMzQxMjczOC4xMzU1\n",
      "Numer 9 o ID: 1004136898\n",
      "We are done\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for offer_url in offer_urls:\n",
    "    print(f\"  Przetwarzam ofertę: {offer_url}\")\n",
    "    counter = counter + 1\n",
    "    driver.get(offer_url)\n",
    "\n",
    "    # Inicjalizacja słownika `data` wszystkimi kluczami z CSV_HEADERS z wartością None\n",
    "    # To zapewnia, że każdy słownik będzie miał te same klucze, nawet jeśli niektóre dane nie zostaną znalezione\n",
    "    offer_data = {header: None for header in CSV_HEADERS}\n",
    "\n",
    "    # Pierwsze miejsce w .csv to id oferty\n",
    "    try:\n",
    "        offer_data['offer_id'] = offer_url.split(',oferta,')[-1].split('?')[0]\n",
    "        print(\"Numer {counter} o ID: {id}\".format(counter = counter, id=offer_data['offer_id']))\n",
    "    except IndexError:\n",
    "        print(f\"Nie udało się wyciągnąć ID z url: {offer_url}\")\n",
    "    # Drugie to url\n",
    "    try:\n",
    "        offer_data['offer_url'] = offer_url\n",
    "    except IndexError:\n",
    "        print(f\"Nie udało się sparsować url: {offer_url}\")\n",
    "\n",
    "    for config_item in SCRAPE_CONFIG:\n",
    "        key_name = config_item['key']\n",
    "        selector = config_item['selector']\n",
    "        method_type = config_item['method']\n",
    "\n",
    "        raw_value = None\n",
    "        # dla elementów które zostaną zapisane w jednym stringu\n",
    "        if method_type == 'element':\n",
    "            raw_value = safe_get_element(driver, By.CSS_SELECTOR, selector)\n",
    "        # dla elementów które zostaną zapisane w liście\n",
    "        elif method_type == 'elements':\n",
    "            raw_value = safe_get_elements(driver, By.CSS_SELECTOR, selector)\n",
    "        # dla elementów posiadających dwa komponenty\n",
    "        elif method_type == 'element_split0':\n",
    "            element = safe_get_element(driver, By.CSS_SELECTOR, selector)\n",
    "            if(element):\n",
    "                try:\n",
    "                    raw_value = safe_get_element(driver, By.CSS_SELECTOR, selector).split('\\n')[0]\n",
    "                except:\n",
    "                    raw_value = None\n",
    "        elif method_type == 'element_split1':\n",
    "            element = safe_get_element(driver, By.CSS_SELECTOR, selector)\n",
    "            if(element):\n",
    "                try:\n",
    "                    raw_value = safe_get_element(driver, By.CSS_SELECTOR, selector).split('\\n')[1]\n",
    "                except:\n",
    "                    raw_value = None\n",
    "        else:\n",
    "            print(f\"Nieznana metoda '{method_type}' dla klucza: '{key_name}'\")\n",
    "            continue # Przejdź do następnego itemu w konfiguracji\n",
    "\n",
    "        offer_data[key_name] = raw_value\n",
    "            \n",
    "    append_dict_to_csv(offer_data, CSV_FILEPATH, CSV_HEADERS)\n",
    "        \n",
    "\n",
    "\n",
    "print(\"We are done\")\n",
    "driver.quit()\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366cc8a-36d5-4431-8c1e-c22d6693cda4",
   "metadata": {},
   "source": [
    "## Definiowane danych z .csv pod analizę\n",
    "\n",
    "Rozpoczynamy od importu pewnych funkcji i definicji tego co analizujemy:\n",
    "* **CSV_FILE** to droga do analizowanej .csv\n",
    "* Kolejne **wyboldowane** punkty to elementy które analizujemy pod względem częstości w kolumnach w naszej .csv (uważać na to w jakim formacie są zapisane, popatrzeć na używaną metodę w **SCRAPE_CONFIG**)\n",
    "* **TOP_N** definiuje podstawową długość listy jaką zbierzemy z .csv, na koniec funkci **analizuj_czestosc** można dodać argument *int* by to zmienić"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50689f32-e700-469c-873b-f566cc675b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import ast # Do bezpiecznej ewaluacji stringów jako list\n",
    "import re # Do czyszczenia danych o wynagrodzeniu\n",
    "\n",
    "CSV_FILE = \"csv_analityk_danych.csv\"\n",
    "\n",
    "IT_SPECIALIZATIONS = 'it_specializations' # np. ['Python', 'SQL']\n",
    "TECHNOLOGIES_EXPECTED = 'technologies_expected' # np. ['AWS', 'Docker']\n",
    "TECHNOLOGIES_OPTIONAL = 'technologies_optional' # np. \"Wymaganie 1\\nWymaganie 2\"\n",
    "BENEFITS = 'benefit_titles' # np. ['Opieka medyczna', 'Karta sportowa']\n",
    "RESPONSIBILITES = 'responsibilities_section'\n",
    "REQUIREMENTS = 'requirements_section'\n",
    "\n",
    "TOP_N = 10 # Ile najczęstszych elementów wyświetlić\n",
    "\n",
    "# Usuwa białe znaki i zmienia wszystko na małe litery\n",
    "\n",
    "def wyczysc_i_znormalizuj_liste(lista_stringow):\n",
    "    if isinstance(lista_stringow, list):\n",
    "        return [str(s).strip().lower() for s in lista_stringow if str(s).strip()]\n",
    "    return []\n",
    "\n",
    "# Przetwarza kolumnę, gdzie każda komórka to string reprezentujący listę (np. \"['Python', 'SQL']\"). Zlicza wystąpienia poszczególnych elementów.\n",
    "\n",
    "def zlicz_elementy_z_list_w_kolumnie(df, nazwa_kolumny, top_n=TOP_N):\n",
    "    wszystkie_elementy = []\n",
    "    stop_words = []\n",
    "    \n",
    "    for _, wiersz in df.iterrows():\n",
    "        elementy_str = wiersz[nazwa_kolumny]\n",
    "        if pd.notna(elementy_str) and isinstance(elementy_str, str) and elementy_str.startswith('[') and elementy_str.endswith(']'):\n",
    "            try:\n",
    "                # Bezpieczna konwersja stringa \"[...]\" na listę Pythona\n",
    "                lista_elementow = ast.literal_eval(elementy_str)\n",
    "                oczyszczone_elementy = [el.strip().lower() \n",
    "                                    for el in lista_elementow \n",
    "                                    if el.strip() and el.strip().lower() not in stop_words]\n",
    "                wszystkie_elementy.extend(wyczysc_i_znormalizuj_liste(oczyszczone_elementy))\n",
    "            except (ValueError, SyntaxError):\n",
    "                print(f\"Ostrzeżenie: Nie udało się sparsować jako listy: {elementy_str} w kolumnie {nazwa_kolumny}\")\n",
    "        elif pd.notna(elementy_str) and isinstance(elementy_str, list): # Jeśli już jest listą\n",
    "             wszystkie_elementy.extend(wyczysc_i_znormalizuj_liste(elementy_str))\n",
    "\n",
    "    licznik = Counter(wszystkie_elementy)\n",
    "    return licznik.most_common(top_n)\n",
    "\n",
    "# Przetwarza kolumnę, gdzie każda komórka to string z elementami oddzielonymi separatorem. Zlicza wystąpienia poszczególnych elementów.\n",
    "\n",
    "def zlicz_elementy_z_tekstu_w_kolumnie(df, nazwa_kolumny, separator='\\n', top_n=TOP_N):\n",
    "    wszystkie_elementy = []\n",
    "    stop_words = ['nasze wymagania','mile widziane','our requirements','optional','wymagania pracodawcy']\n",
    "\n",
    "    for _, wiersz in df.iterrows():\n",
    "        tekst_elementow = wiersz[nazwa_kolumny]\n",
    "        if pd.notna(tekst_elementow) and isinstance(tekst_elementow, str):\n",
    "            lista_elementow = tekst_elementow.split(separator)\n",
    "            # Usuwamy puste stringi po splicie, normalizujemy i porównujemy ze stop_words\n",
    "            oczyszczone_elementy = [el.strip().lower() \n",
    "                                    for el in lista_elementow \n",
    "                                    if el.strip() and el.strip().lower() not in stop_words]\n",
    "            wszystkie_elementy.extend(oczyszczone_elementy)\n",
    "\n",
    "    licznik = Counter(wszystkie_elementy)\n",
    "    return licznik.most_common(top_n)\n",
    "\n",
    "# Funkcja, która prezentuje dla nazwa_kolumny w zależności od zdefiniowanej dla niej w SCRAPE_CONFIG metody\n",
    "\n",
    "def analizuj_czestosc(metoda, df, nazwa_kolumny, top_n=TOP_N):\n",
    "    print(f\"\\n Najczęściej występujące {nazwa_kolumny}: (TOP {top_n}):\")\n",
    "    if(metoda =='lista'):\n",
    "        wyswietlane = zlicz_elementy_z_list_w_kolumnie(df, nazwa_kolumny, top_n)\n",
    "        if wyswietlane:\n",
    "            for co, ile in wyswietlane:\n",
    "                print(f\"- {co}: {ile} razy\")\n",
    "        else:\n",
    "            print(\"Brak danych lub nie udało się przetworzyć.\")\n",
    "    elif(metoda =='tekst'):\n",
    "        wyswietlane = zlicz_elementy_z_tekstu_w_kolumnie(df, nazwa_kolumny,'\\n', top_n)\n",
    "        if wyswietlane:\n",
    "            for co, ile in wyswietlane:\n",
    "                print(f\"- {co}: {ile} razy\")\n",
    "        else:\n",
    "            print(\"Brak danych lub nie udało się przetworzyć.\")\n",
    "    else:\n",
    "        print(\"Niepoprawna metoda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee33a6b-c8bb-4367-8329-cfa41470a51f",
   "metadata": {},
   "source": [
    "## Rzeczywista analiza\n",
    "\n",
    "Wczytujemy plik i stosujemy funkcję **analizuj_czestosc** by wytypować najczęściej powtarzające się frazy/elementy. Argumentów **lista** i **tekst** używamy w zależności od metody zdefiniowanej dla danej kolumny w **SCRAPE_CONFIG**. Podajemy nazwę kolumny jak zdefiniowaliśmy powyżej. Możemy jeszcze dodać 4 argument typu *int*, który zmieni ilość wyświetlanych elementów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9788203d-6ea3-4b01-814d-aca7e052e459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analiza pliku: csv_analityk_danych.csv\n",
      "--------------------------------------------------\n",
      "\n",
      " Najczęściej występujące technologies_expected: (TOP 10):\n",
      "- sql: 7 razy\n",
      "- microsoft excel: 5 razy\n",
      "- postgresql: 4 razy\n",
      "- python: 4 razy\n",
      "- mysql: 3 razy\n",
      "- php: 2 razy\n",
      "- html: 2 razy\n",
      "- css: 2 razy\n",
      "- javascript: 2 razy\n",
      "- scss: 2 razy\n",
      "\n",
      " Najczęściej występujące technologies_optional: (TOP 10):\n",
      "- python: 3 razy\n",
      "- react.js: 2 razy\n",
      "- nextjs: 2 razy\n",
      "- postgresql: 2 razy\n",
      "- microsoft sql server: 2 razy\n",
      "- apache spark: 2 razy\n",
      "- databricks: 2 razy\n",
      "- azure devops: 2 razy\n",
      "- apache airflow: 2 razy\n",
      "- jira: 2 razy\n",
      "\n",
      " Najczęściej występujące requirements_section: (TOP 10):\n",
      "- umiejętność analitycznego myślenia: 3 razy\n",
      "- advanced level of english (read, written): 3 razy\n",
      "- excellent communication skills on different business levels with ability to build partnership business relations: 3 razy\n",
      "- knowledge about lean and continuous improvements: 3 razy\n",
      "- knowledge of microsoft office tools (ms excel, word, powerpoint): 3 razy\n",
      "- preferable previous experience in a back-office position: 3 razy\n",
      "- doświadczenie (1-2 lata) w tworzeniu aplikacji webowych (m.in. php, html5, javascript, css3, css3: scss): 2 razy\n",
      "- znajomość framework jquery, bootstrap: 2 razy\n",
      "- znajomość wordpress (znajomość innych platform mile widziana): 2 razy\n",
      "- znajomość różnic i praktyczna umiejętność kodowania rwd: 2 razy\n",
      "\n",
      " Najczęściej występujące benefit_titles: (TOP 10):\n",
      "- prywatna opieka medyczna: 55 razy\n",
      "- dofinansowanie zajęć sportowych: 54 razy\n",
      "- ubezpieczenie na życie: 41 razy\n",
      "- spotkania integracyjne: 33 razy\n",
      "- dofinansowanie szkoleń i kursów: 32 razy\n",
      "- kawa / herbata: 29 razy\n",
      "- program rekomendacji pracowników: 29 razy\n",
      "- elastyczny czas pracy: 27 razy\n",
      "- możliwość pracy zdalnej: 24 razy\n",
      "- zniżki na firmowe produkty i usługi: 23 razy\n",
      "\n",
      " Najczęściej występujące it_specializations: (TOP 10):\n",
      "- specializations:\n",
      "business analytics: 4 razy\n",
      "- specjalizacje:\n",
      "big data / data science: 4 razy\n",
      "- specjalizacje:\n",
      "frontend, ux/ui: 2 razy\n",
      "- specializations:\n",
      "big data / data science: 2 razy\n",
      "- specjalizacje:\n",
      "business analytics: 2 razy\n",
      "- specjalizacje:\n",
      "system analytics: 2 razy\n",
      "- specializations:\n",
      "system analytics: 1 razy\n",
      "- specjalizacje:\n",
      "big data / data science, system analytics: 1 razy\n",
      "- specjalizacje:\n",
      "big data / data science, business analytics: 1 razy\n",
      "- specjalizacje:\n",
      "devops, it admin: 1 razy\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(CSV_FILE)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Błąd: Nie znaleziono pliku {CSV_FILE}. Upewnij się, że plik istnieje i ścieżka jest poprawna.\")\n",
    "except Exception as e:\n",
    "    print(f\"Błąd podczas wczytywania pliku CSV: {e}\")\n",
    "\n",
    "print(f\"Analiza pliku: {CSV_FILE}\")\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "analizuj_czestosc(\"lista\", df, TECHNOLOGIES_EXPECTED)\n",
    "analizuj_czestosc(\"lista\", df, TECHNOLOGIES_OPTIONAL)\n",
    "analizuj_czestosc(\"tekst\", df, REQUIREMENTS)\n",
    "analizuj_czestosc(\"lista\", df, BENEFITS)\n",
    "analizuj_czestosc(\"lista\", df, IT_SPECIALIZATIONS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
